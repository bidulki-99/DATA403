{"cells":[{"cell_type":"markdown","id":"4d162c7a","metadata":{"id":"4d162c7a"},"source":["# Import Packages for Actor-Critic"]},{"cell_type":"code","source":["!pip install gymnasium"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AIHOQvB_dnAn","executionInfo":{"status":"ok","timestamp":1684896192866,"user_tz":-540,"elapsed":5535,"user":{"displayName":"윤민서","userId":"16983864168157635834"}},"outputId":"fbb747c3-f95a-4f94-eaf5-9857ab26bff1"},"id":"AIHOQvB_dnAn","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.28.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.22.4)\n","Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.0.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"]}]},{"cell_type":"code","execution_count":2,"id":"6ba41c5e","metadata":{"id":"6ba41c5e","executionInfo":{"status":"ok","timestamp":1684896192867,"user_tz":-540,"elapsed":7,"user":{"displayName":"윤민서","userId":"16983864168157635834"}}},"outputs":[],"source":["import gymnasium as gym\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.distributions import Categorical\n","\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","id":"9ffb6c2e","metadata":{"id":"9ffb6c2e"},"source":["# We'll use OmegaConf to manage hyperparameters!"]},{"cell_type":"code","execution_count":3,"id":"adcab78c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adcab78c","executionInfo":{"status":"ok","timestamp":1684896196659,"user_tz":-540,"elapsed":3798,"user":{"displayName":"윤민서","userId":"16983864168157635834"}},"outputId":"f7bb9612-d261-4a64-9bfb-15de23e2ae75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0)\n"]}],"source":["!pip install omegaconf"]},{"cell_type":"code","execution_count":4,"id":"d4abeede","metadata":{"id":"d4abeede","executionInfo":{"status":"ok","timestamp":1684896196660,"user_tz":-540,"elapsed":35,"user":{"displayName":"윤민서","userId":"16983864168157635834"}}},"outputs":[],"source":["from omegaconf import OmegaConf"]},{"cell_type":"markdown","id":"980d6788","metadata":{"id":"980d6788"},"source":["# Environment\n","- CartPole-v1"]},{"cell_type":"code","execution_count":5,"id":"7c61623a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7c61623a","executionInfo":{"status":"ok","timestamp":1684896196661,"user_tz":-540,"elapsed":35,"user":{"displayName":"윤민서","userId":"16983864168157635834"}},"outputId":"956785df-e49a-4949-8458-f1f94d051931"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TimeLimit<OrderEnforcing<PassiveEnvChecker<CartPoleEnv<CartPole-v1>>>>>"]},"metadata":{},"execution_count":5}],"source":["env = gym.make('CartPole-v1')\n","env"]},{"cell_type":"markdown","id":"76967dc5","metadata":{"id":"76967dc5"},"source":["# Hyperparameters"]},{"cell_type":"code","execution_count":6,"id":"44907bb4","metadata":{"id":"44907bb4","executionInfo":{"status":"ok","timestamp":1684896196661,"user_tz":-540,"elapsed":30,"user":{"displayName":"윤민서","userId":"16983864168157635834"}}},"outputs":[],"source":["AC_config = OmegaConf.create({\n","    # DQN parameters\n","    'gamma': 0.99,\n","    \n","    # policy network parameters\n","    'device': 'cuda:0',\n","    'hidden_dim': 64,\n","    'state_dim': env.observation_space.shape[0],\n","    'action_dim': int(env.action_space.n),\n","\n","    # learning parameters\n","    'learning_rate': 0.0001,\n","    'n_rollout': 10,\n","})"]},{"cell_type":"code","execution_count":7,"id":"c312dded","metadata":{"id":"c312dded","executionInfo":{"status":"ok","timestamp":1684896196662,"user_tz":-540,"elapsed":31,"user":{"displayName":"윤민서","userId":"16983864168157635834"}}},"outputs":[],"source":["class ActorCritic(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.data = []\n","        self.config = config\n","        \n","        # actor network\n","        self.actor = nn.Sequential(\n","            nn.Linear(self.config.state_dim, self.config.hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(self.config.hidden_dim, self.config.action_dim),\n","            nn.Softmax(dim=-1)\n","        )\n","        \n","        # critic network\n","        self.critic = nn.Sequential(\n","            nn.Linear(self.config.state_dim, self.config.hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(self.config.hidden_dim, 1)\n","        )\n","        \n","        # load them to gpu (if available)\n","        self.to(self.config.device)\n","        \n","        # optimizer\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.config.learning_rate)\n","    \n","    def actor_forward(self, state):\n","        return self.actor(state)\n","\n","    def critic_forward(self, state):\n","        return self.critic(state)\n","    \n","    # add transition data\n","    def put_data(self, transition):\n","        self.data.append(transition)\n","        \n","    # convert transitions to batch data\n","    def make_batch(self):\n","        state_list, action_list, reward_list, next_state_list, terminated_list = [], [], [], [], []\n","        for transition in self.data:\n","            state, action, reward, next_state, termindated = transition\n","            \n","            state_list.append(list(state))\n","            action_list.append([action])\n","            reward_list.append([reward / 100.0])\n","            next_state_list.append(list(next_state))\n","            termindated_mask = 0.0 if termindated else 1.0\n","            terminated_list.append([termindated_mask])\n","        \n","        state_batch = torch.tensor(state_list, dtype=torch.float).to(self.config.device)\n","        action_batch = torch.tensor(action_list).to(self.config.device)\n","        reward_batch = torch.tensor(reward_list, dtype=torch.float).to(self.config.device)\n","        next_state_batch = torch.tensor(next_state_list, dtype=torch.float).to(self.config.device)\n","        terminated_batch = torch.tensor(terminated_list, dtype=torch.float).to(self.config.device)\n","        \n","        # clear buffer\n","        self.data = []\n","        \n","        return state_batch, action_batch, reward_batch, next_state_batch, terminated_batch\n","  \n","    def update(self):\n","        # get data using self.make_batch()\n","        states, actions, rewards, next_states, terminated = self.make_batch()\n","\n","        # compute TD target\n","        td_target = rewards + self.config.gamma * self.critic(next_states) * terminated\n","\n","        # compute TD error\n","        td_error = td_target - self.critic(states)\n","\n","        # compute Actor loss\n","        action_probs = self.actor(states).gather(1, actions)\n","        actor_loss = -torch.log(action_probs) * td_error.detach()\n","\n","        # compute Critic loss\n","        critic_loss = F.smooth_l1_loss(self.critic(states), td_target.detach())\n","\n","        # Aggregate\n","        loss = actor_loss + critic_loss\n","\n","        # backpropagation\n","        self.optimizer.zero_grad()\n","        loss.mean().backward()\n","        self.optimizer.step()"]},{"cell_type":"code","execution_count":null,"id":"ad721a29","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ad721a29","outputId":"b5a32f01-7f3f-4b5f-f030-09b3b08e277f"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 1516/10000 [01:16<13:10, 10.73it/s]"]}],"source":["num_epis, epi_rews = 10000, []\n","agent = ActorCritic(AC_config)\n","\n","for n_epi in tqdm(range(num_epis)):\n","    state, _ = env.reset()\n","    terminated, truncated = False, False\n","    epi_rew = 0\n","    \n","    while not (terminated or truncated):\n","        for t in range(AC_config.n_rollout):\n","            # get action probs from actor & sample -- use Categorical!\n","            action_probs = agent.actor(torch.from_numpy(state).float().to(AC_config.device))\n","            action_dist = Categorical(action_probs)\n","            action = action_dist.sample()\n","\n","            # step\n","            next_state, reward, terminated, truncated, _ = env.step(action.item())\n","            \n","            # collect transition\n","            agent.put_data((state, action, reward, next_state, terminated or truncated))\n","            \n","            # state transition\n","            state = next_state\n","            \n","            # record reward\n","            epi_rew += reward\n","            \n","            if terminated or truncated:\n","                break\n","            \n","        # update\n","        agent.update()\n","        \n","    # record\n","    epi_rews += [epi_rew]\n","    \n","env.close()"]},{"cell_type":"code","execution_count":null,"id":"d1808324","metadata":{"id":"d1808324"},"outputs":[],"source":["plt.figure(figsize=(20, 10), dpi=300)\n","plt.plot(epi_rews, label='episode returns')\n","plt.legend(fontsize=20)\n","plt.show()\n","plt.close()"]},{"cell_type":"code","source":[],"metadata":{"id":"x9-3upOao5I5"},"id":"x9-3upOao5I5","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}