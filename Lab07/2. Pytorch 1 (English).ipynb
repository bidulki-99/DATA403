{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Basic  \n",
    "![](_2023-04-17-13-59-20.png)  \n",
    "\n",
    "Writer: KukJin Kim kukjinkim@korea.ac.kr  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](_2023-04-17-13-37-23.png)  \n",
    "\n",
    "Is ChatGPT really implemented in Pytorch?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- Class Review \n",
    "- Data representation with tensor <-\n",
    "- Tensor Manipulation <-\n",
    "- Dataset, DataLoader\n",
    "- Regresseion \n",
    "- Clasification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 2016, deep learning and reinforcement learning have developed at a really fast pace, resulting in innovative products such as the current ChatGPT.  \n",
    "In this practice, we will practice in earnest the Pytorch deep learning framework, which is very widely used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A GPU is required for this exercise. If your laptop does not have a GPU, you can solve this by replacing all device code with cpu. Or, please practice on Colab and change the runtime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](2023-04-25-21-42-12.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-04-25-21-43-14.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data representation with tensor  \n",
    "In linear algebra, you learn about the concepts of scalars, vectors, matrices, and tensors.  \n",
    "Linear algebra books and many machine learning books denote them with the following symbols  \n",
    "Let's see how to manipulate tensors in PyTorch through several modules and methods.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Scalar} : x\\quad 0 \\  \\text{(0-dimension) }$$\n",
    "$$\\text{Vector} : \\mathbf x \\quad n \\ \\text{ (1-dimension)}$$\n",
    "$$\\text{Matrix} : \\mathbf X \\quad m \\times n \\  \\text {(2-dimension)}$$\n",
    "$$\\text{Tensor} : \\mathcal {X} \\quad l \\times m \\times n \\times \\dots \\text {(more 3-dimension)} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-04-25-21-44-38.png)\n",
    "\n",
    "(https://furkangulsen.medium.com/what-is-a-tensor-ce8e78835d08)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recall the types of data we learn at the beginning of programming courses.\n",
    "Typical examples include:\n",
    "1. Int  \n",
    "2. Double  \n",
    "3. Float  \n",
    "\n",
    "Similarly, you can create tensors with the above data types through various tensor modules of torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "from torch import FloatTensor as ftensor\n",
    "from torch import DoubleTensor as dtensor\n",
    "from torch import IntTensor as itensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Scalar\n",
    "`torch.tensor(data)` takes a data array as input and returns a tensor object from pytorch.  \n",
    "    \n",
    "   \n",
    "Tensor objects are allocated in the following form.  \n",
    "`tensor = torch.tensor(data, dtype=float32, device='cpu')`  \n",
    "   \n",
    "  \n",
    "Parameters and arguments for creating a tensor object include data, dtype, and device.  \n",
    "data can contain lists or numpy arrays, device can contain a gpu index such as cuda:0 or cpu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, if no argument is given, the tensor is calculated with cpu, and the data type is set to float32 or int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "cpu\n",
      "torch.float32\n",
      "tensor(2, device='cuda:0')\n",
      "cuda:0\n",
      "torch.int64\n",
      "1.0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor(1.0)\n",
    "print(tensor1)\n",
    "print(tensor1.device)\n",
    "print(tensor1.dtype)\n",
    "\n",
    "tensor2 = torch.tensor(2, device='cuda')\n",
    "print(tensor2)\n",
    "print(tensor2.device)\n",
    "print(tensor2.dtype)\n",
    "\n",
    "# For plotting value\n",
    "print(tensor1.item())\n",
    "print(tensor2.item())\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to remember here are:\n",
    "- Both the dtype and device of tensor objects must be unified\n",
    "- That is, the data type of the input tensor and the data type of the model weight tensor must be the same.\n",
    "- In addition, the input tensor and model weight tensor calculation device must be the same.\n",
    "\n",
    "If the above is not followed, pytorch internally converts the device and dtype to perform the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3., device='cuda:0')\n",
      "cuda:0\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor3 = tensor1 + tensor2\n",
    "print(tensor3)\n",
    "print(tensor3.device)\n",
    "print(tensor3.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vec = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In numpy, you represent vectors or tensors by putting sequence data (lists, tuples).  \n",
    "In `torch.tensor(data)`, the containers can be List, Tuple, and Numpy array.  \n",
    "Creating tensor objects in PyTorch is very similar to existing numpy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0000, -1.1000,  3.9000])\n",
      "torch.float32\n",
      "tensor([ 1.0000, -1.1000,  3.9000], dtype=torch.float64)\n",
      "tensor([1, 2, 3, 4], dtype=torch.int32)\n",
      "tensor([ 1, -1,  3])\n"
     ]
    }
   ],
   "source": [
    "vec1 = ftensor([1.0, -1.1, 3.9]) # list input\n",
    "vec2 = dtensor((1.0, -1.1, 3.9)) # Tuple input\n",
    "vec3 = tensor(np.array([1, 2, 3, 4])) # numpy ary input\n",
    "vec4 = tensor([1.0, -1.1, 3.9], dtype=int)\n",
    "\n",
    "print(vec1)\n",
    "print(vec1.dtype)\n",
    "print(vec2)\n",
    "print(vec3)\n",
    "print(vec4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Matrix  \n",
    "Now let's create a matrix tensor.  \n",
    "If you start dealing with datatypes as matrices, it's a good idea to designate the device as a gpu for parallel processing.  \n",
    "Now, since it is difficult to generate the data manually, we will use rand.  \n",
    "Let's fix the seed to make same results of rand function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a5832a96f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1) # torch.manual_seed(seed) fixing random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8903, 0.0275],\n",
      "        [0.9031, 0.5386]], device='cuda:0')\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "mat = torch.rand([2, 2], device='cuda')\n",
    "print(mat)\n",
    "print(mat.device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Tensor\n",
    "Now let's create a tensor of more than three dimensions.  \n",
    "'to(dtype=dtype, device=device)' : This method returns the desired data type, the tensor of the desired device, as a method within the tenso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[157.3619,  97.5393, 163.1013],\n",
      "         [121.4620, 182.6800, 158.4733],\n",
      "         [113.2884,  24.5168, 157.2242],\n",
      "         [ 14.6759, 144.8228, 136.5066],\n",
      "         [ 99.8530, 232.6652, 136.5423],\n",
      "         [181.0788, 182.1689,  52.4888],\n",
      "         [ 78.7924, 251.0999,   2.6269],\n",
      "         [119.3065, 117.8560, 218.7916],\n",
      "         [115.8311, 161.7047, 121.8555],\n",
      "         [ 56.3268,  55.4509,  65.8133],\n",
      "         [ 11.7242,  44.9303, 158.1247],\n",
      "         [212.2427, 134.3056,  69.3261],\n",
      "         [184.2539,  78.8643,  99.6456],\n",
      "         [ 57.8295,  87.8077,   9.3952],\n",
      "         [182.6163, 177.7710, 153.4251],\n",
      "         [190.8456, 182.2505, 133.6631],\n",
      "         [141.5559, 137.7742, 196.3005],\n",
      "         [213.9836, 219.9226, 202.1895],\n",
      "         [ 96.7924, 122.3017, 101.9875],\n",
      "         [202.4617, 142.2154, 246.4687],\n",
      "         [192.9206,  18.6036, 165.4441],\n",
      "         [250.9919, 241.6952, 125.9885],\n",
      "         [170.4645,   7.9294,  87.1935],\n",
      "         [190.4178,  11.3967, 239.5140],\n",
      "         [ 43.8241, 168.4765, 123.1541],\n",
      "         [150.5558, 140.4013,   8.3414],\n",
      "         [100.5056,  47.0898, 236.8197],\n",
      "         [112.2881,   0.5481, 159.0015],\n",
      "         [183.5866,  70.6997, 115.9926],\n",
      "         [183.3357,  48.3575,  60.3371],\n",
      "         [115.6523,  38.1115, 206.6686],\n",
      "         [138.4693, 204.5829, 196.5255],\n",
      "         [ 29.3553,  48.2183,  40.4503],\n",
      "         [ 86.8607,  81.2257, 107.3753],\n",
      "         [  4.1727, 182.0540, 200.6152],\n",
      "         [168.5674, 209.3385, 224.1575],\n",
      "         [  1.6416, 147.3351, 246.7343],\n",
      "         [ 35.2363,  71.0074, 121.2593],\n",
      "         [ 48.3733, 103.8743, 109.0854],\n",
      "         [242.0443, 119.9515, 197.4108],\n",
      "         [221.7313, 185.0269,  16.6867],\n",
      "         [223.9366, 212.4096,  36.2417],\n",
      "         [ 82.3588, 215.1206,   3.5706],\n",
      "         [ 15.8123,  41.2469, 167.8847],\n",
      "         [ 75.7288,  13.8444, 177.6167],\n",
      "         [192.7454, 175.9440,  18.3331],\n",
      "         [252.6359, 118.3424,   6.1728],\n",
      "         [108.7307, 211.6037, 186.9477],\n",
      "         [126.6320, 218.2348,  11.2154],\n",
      "         [216.8122, 255.0596,  50.1677],\n",
      "         [155.4554, 107.3592,  19.9437],\n",
      "         [126.8779,  85.1043,  18.6695],\n",
      "         [ 34.7304, 130.7930, 246.6645],\n",
      "         [173.8281,  42.8369, 216.2877],\n",
      "         [138.5067,   2.9256, 134.0717],\n",
      "         [210.1685,  52.7353, 122.1105],\n",
      "         [ 64.2282,  27.0711,  55.2687],\n",
      "         [140.8536, 210.7410, 104.2147],\n",
      "         [ 12.8880, 126.9043,  16.6750],\n",
      "         [135.5190, 222.9021, 182.6284],\n",
      "         [ 49.7106,  99.7507, 179.2545],\n",
      "         [162.7243,   7.7663,  53.3739],\n",
      "         [ 82.7316, 175.0387, 242.3684],\n",
      "         [185.0385, 176.3532,  19.3843]]])\n",
      "torch.float32\n",
      "tensor([[[157,  97, 163],\n",
      "         [121, 182, 158],\n",
      "         [113,  24, 157],\n",
      "         [ 14, 144, 136],\n",
      "         [ 99, 232, 136],\n",
      "         [181, 182,  52],\n",
      "         [ 78, 251,   2],\n",
      "         [119, 117, 218],\n",
      "         [115, 161, 121],\n",
      "         [ 56,  55,  65],\n",
      "         [ 11,  44, 158],\n",
      "         [212, 134,  69],\n",
      "         [184,  78,  99],\n",
      "         [ 57,  87,   9],\n",
      "         [182, 177, 153],\n",
      "         [190, 182, 133],\n",
      "         [141, 137, 196],\n",
      "         [213, 219, 202],\n",
      "         [ 96, 122, 101],\n",
      "         [202, 142, 246],\n",
      "         [192,  18, 165],\n",
      "         [250, 241, 125],\n",
      "         [170,   7,  87],\n",
      "         [190,  11, 239],\n",
      "         [ 43, 168, 123],\n",
      "         [150, 140,   8],\n",
      "         [100,  47, 236],\n",
      "         [112,   0, 159],\n",
      "         [183,  70, 115],\n",
      "         [183,  48,  60],\n",
      "         [115,  38, 206],\n",
      "         [138, 204, 196],\n",
      "         [ 29,  48,  40],\n",
      "         [ 86,  81, 107],\n",
      "         [  4, 182, 200],\n",
      "         [168, 209, 224],\n",
      "         [  1, 147, 246],\n",
      "         [ 35,  71, 121],\n",
      "         [ 48, 103, 109],\n",
      "         [242, 119, 197],\n",
      "         [221, 185,  16],\n",
      "         [223, 212,  36],\n",
      "         [ 82, 215,   3],\n",
      "         [ 15,  41, 167],\n",
      "         [ 75,  13, 177],\n",
      "         [192, 175,  18],\n",
      "         [252, 118,   6],\n",
      "         [108, 211, 186],\n",
      "         [126, 218,  11],\n",
      "         [216, 255,  50],\n",
      "         [155, 107,  19],\n",
      "         [126,  85,  18],\n",
      "         [ 34, 130, 246],\n",
      "         [173,  42, 216],\n",
      "         [138,   2, 134],\n",
      "         [210,  52, 122],\n",
      "         [ 64,  27,  55],\n",
      "         [140, 210, 104],\n",
      "         [ 12, 126,  16],\n",
      "         [135, 222, 182],\n",
      "         [ 49,  99, 179],\n",
      "         [162,   7,  53],\n",
      "         [ 82, 175, 242],\n",
      "         [185, 176,  19]]], device='cuda:0')\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "# T = torch.rand([64, 64, 3], device='cuda:0')\n",
    "T = torch.rand([64, 64, 3], device='cpu')\n",
    "T = T * 256\n",
    "print(T[0:1])\n",
    "print(T.dtype)\n",
    "\n",
    "T = T.to(int) \n",
    "T = T.to(device='cuda:0')\n",
    "print(T[0:1])\n",
    "print(T.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pop Quiz 1 (Easy)  \n",
    "1) !Check the memory capacity and current usage of gpu through `nvidia-smi`\n",
    "2) Create a four-dimensional random tensor of size (1000, 64, 64, 3) and assign it to gpu memory\n",
    "3) Calculate again how much gpu memory usage has increased through `nvidia-smi`\n",
    "\n",
    "#### If your laptop doesn't have a GPU, set the CPU to device and check the memory usage through the task manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "4d_tensor = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tensor manipulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear algebra, we learn how to add, subtract, inner product and outer product of two vectors, and we learn matrix operations such as addition, subtraction, multiplication, and inverse matrix calculation. All of these vectors, matrices, and tensor operations can similarly be performed on the pytorch. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Vector, Matrix, Tensor Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32)\n"
     ]
    }
   ],
   "source": [
    "# Vector Inner Product\n",
    "vec1 = tensor([1, 2, 3])\n",
    "vec2 = tensor([4, 5, 6])\n",
    "# For dot product of vectors, use the torch.dot method or the tensor.dot method.\n",
    "vec3 = vec1.dot(vec2) # 1 * 4 + 2 * 5 + 3 * 6\n",
    "print(vec3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3,  6, -3])\n"
     ]
    }
   ],
   "source": [
    "# Vector Cross Product\n",
    "crosse_vec = torch.cross(vec1, vec2) # The length of the vector must be three dimensions.\n",
    "print(crosse_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  5,  6],\n",
      "        [ 8, 10, 12],\n",
      "        [12, 15, 18]])\n"
     ]
    }
   ],
   "source": [
    "# Vector Outer Product\n",
    "outer_vec = torch.outer(vec1, vec2) # Calculates the outer part of the vector. The output is a matrix.\n",
    "print(outer_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "# * :asterisk This symbol performs elementwise product.\n",
    "vec4 = vec1 * vec2\n",
    "print(vec4) # [4, 10, 18]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n"
     ]
    }
   ],
   "source": [
    "# Any tensor can be element multiplied via the asterisk symbol.\n",
    "mat1 = tensor([[1, 2], \n",
    "              [3, 4]])\n",
    "mat2 = tensor([[5, 6], \n",
    "              [7, 8]])\n",
    "print(mat1 * mat2) # 5, 12, 21, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[[  7,  10],\n",
      "         [ 15,  22]],\n",
      "\n",
      "        [[ 67,  78],\n",
      "         [ 91, 106]]])\n",
      "tensor([[[  7,  10],\n",
      "         [ 15,  22]],\n",
      "\n",
      "        [[ 67,  78],\n",
      "         [ 91, 106]]])\n"
     ]
    }
   ],
   "source": [
    "# at sign @ : The symbol of the golbang performs matrix multiplication.\n",
    "# Matrix multiplication can also be calculated using the matmul function.\n",
    "\n",
    "mat4 = mat1 @ mat2\n",
    "mat5 = mat1.matmul(mat2)\n",
    "print(mat4)\n",
    "print(mat5)\n",
    "\n",
    "ten1 = tensor([[[1, 2], \n",
    "              [3, 4]],\n",
    "                [[5, 6], \n",
    "              [7, 8]]])\n",
    "ten2 = tensor([[[1, 2], \n",
    "              [3, 4]],\n",
    "                [[5, 6], \n",
    "              [7, 8]]])\n",
    "\n",
    "a = ten1.matmul(ten2)\n",
    "b = ten1 @ ten2\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[-2.3838, -1.8098, -1.3820, -2.1522],\n",
      "        [ 0.1541, -1.0625,  0.1794, -0.5829],\n",
      "        [ 0.1726,  0.1184, -0.5380,  0.1871],\n",
      "        [ 0.5071,  0.0385,  1.2226, -0.0821]])\n",
      "tensor([-2.3838, -1.0625, -0.5380, -0.0821])\n"
     ]
    }
   ],
   "source": [
    "# The identity matrix can be created through  .eye(shape).\n",
    "eye_tensor = torch.eye(2)\n",
    "print(eye_tensor.shape)\n",
    "\n",
    "# diagnomal elemeents through torch.diag(matrix)\n",
    "v = torch.randn([4,4])\n",
    "print(v)\n",
    "diag_vector = torch.diag(v)\n",
    "print(diag_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 50,  60],\n",
      "        [114, 140]])\n"
     ]
    }
   ],
   "source": [
    "# tensor dot\n",
    "print(torch.tensordot(ten1, ten2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 * **Tensor dimension manipulation** * (Very important!)  \n",
    "To input data into a deep learning model, we really need to deal with the dimensions of the tensor.  \n",
    "Methods for manipulating dimensions are as follows.  \n",
    "1) Dimension reduction, expansion: `squeeze(), unsqueeze()` removes or adds dimensions of axis in which size is 1.  \n",
    "2) Dimension exchange: `transpose(), permute()` : Change the order of the dimensions. It is usually used to handle tensors that are more than three dimensions.  \n",
    "3) Changing tensor shape : `flatten(), view(), reshape()`  \n",
    "4) Tensor concatenation and stacking: `cat(), stack()`  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Dimension reduction, extension\n",
    "The `tensor.squeeze(axis)` or `torch.squeeze(axis)` function removes a specific axis corresponding to the axis value.  \n",
    "The `tensor.unsqueeze(axis)` or `torch.unsqueeze(axis)` function adds a dimension to the axis corresponding to the axis value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1, 1])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "vec1 = tensor([1, 2, 3])\n",
    "print(vec1.shape)\n",
    "unsq_vec1 = vec1.unsqueeze(1)\n",
    "print(unsq_vec1.shape)\n",
    "unsq_vec1 = unsq_vec1.unsqueeze(1)\n",
    "print(unsq_vec1.shape)\n",
    "sq_vec1 = unsq_vec1.squeeze(2)\n",
    "print(sq_vec1.shape)\n",
    "sq_vec1 = sq_vec1.squeeze(1)\n",
    "print(sq_vec1.shape)\n",
    "sq_vec1 = sq_vec1.squeeze()\n",
    "print(sq_vec1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 1, 1, 64, 64, 3])\n",
      "torch.Size([10, 32, 1, 1, 64, 64, 3])\n",
      "torch.Size([10, 32, 1, 64, 64, 3])\n",
      "torch.Size([10, 32, 64, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "# Easily create tensors with all values of 1 via torch.ones(shape)\n",
    "tensor_7d = torch.ones([10, 32, 1, 1, 64, 64, 3])\n",
    "tensor_7d = torch.zeros([10, 32, 1, 1, 64, 64, 3])\n",
    "\n",
    "\n",
    "# Use the `ones_like` method when it is cumbersome to input the shape of a dimension individually.\n",
    "tensor_7d2 = torch.ones_like(tensor_7d)\n",
    "tensor_7d3 = torch.zeros_like(tensor_7d)\n",
    "print(tensor_7d.shape)\n",
    "print(tensor_7d2.shape)\n",
    "\n",
    "tensor_6d = tensor_7d.squeeze(axis=2) # Remove the axis corresponding to the 2nd index from shape.\n",
    "print(tensor_6d.shape) # [10, 32, 1, 64, 64, 3]\n",
    "tensor_5d = tensor_7d.squeeze()\n",
    "print(tensor_5d.shape) # [10, 32, 64, 64, 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 64, 64])\n",
      "torch.Size([1, 32, 3, 64, 64])\n",
      "torch.Size([32, 3, 64, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor_4d = torch.ones([32, 3, 64, 64])\n",
    "print(tensor_4d.shape)\n",
    "\n",
    "tensor_5d = tensor_4d.unsqueeze(0)\n",
    "tensor_5d2 = tensor_4d.unsqueeze(4) # = -1 \n",
    "print(tensor_5d.shape)\n",
    "print(tensor_5d2.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Dimension exchange: ` transpose(), permute()  `\n",
    "The methods above are used to swap dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.ones([2, 3])\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([6, 2, 4, 11])\n"
     ]
    }
   ],
   "source": [
    "# torch.transpose(input, dim0, dim1) swaps two dimensions of the input tensor.\n",
    "# Available by calling tensor.transpose() or via torch.transpose().\n",
    "transposed = torch.transpose(matrix, 0, 1)\n",
    "print(transposed.shape)\n",
    "transposed2 = matrix.transpose(0, 1)\n",
    "print(transposed2.shape)\n",
    "\n",
    "tensor_4d = torch.ones([4, 2, 6, 11])\n",
    "transposed_4d = tensor_4d.transpose(0, 2)\n",
    "print(transposed_4d.shape) # 6, 2, 4, 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 6, 4, 2])\n",
      "torch.Size([2, 4, 6, 11])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute() : Super version method of transpose. List the dimension axis order as desired.\n",
    "\n",
    "permuted_4d = torch.permute(tensor_4d, [3, 2, 0, 1])\n",
    "print(permuted_4d.shape)\n",
    "permuted_4d2 = torch.permute(tensor_4d, (1, 0, 2, 3))\n",
    "print(permuted_4d2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pop Quiz 2 (Easy)   \n",
    "Add a redundancy dimension to the 0th axis of `tensor_4d` and swap the 0th and 2nd dimensions using `permute()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code implementation\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Changing the shape of tensor  : `flatten(),  reshape(), view()`  \n",
    "The above three methods are mainly used when exchanging data between the CNN layer and the FC layer.  \n",
    "Or, these are often used when changing the shape of an input tensor.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.flatten()` The method converts the entire tensor into a 1D vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "t = tensor([[[1, 2],\n",
    "            [3, 4]],\n",
    "           [[5, 6],\n",
    "           [7, 8]]])\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "flattened_t = torch.flatten(t)\n",
    "print(flattened_t)\n",
    "print(flattened_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 만약에 start_dim, end_dim이 주어지면 해당하는 차원부터 flatten합니다.\n",
    "flattened_t2 = torch.flatten(t, start_dim=2)\n",
    "print(flattened_t2)\n",
    "print(flattened_t2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reshape()` This method adjusts the dimensions of the tensor to have the desired shape.  \n",
    "However, at this time, the product of total shape of each dimension must match the original dimension. ex 8 -> 2, 2, 2 or 4, 2  \n",
    "If -1 is entered, the corresponding dimension is automatically calculated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.arange(36)\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "reshaped_t = t2.reshape(3, 3, 4)\n",
    "print(reshaped_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 2])\n"
     ]
    }
   ],
   "source": [
    "reshaped_t = t2.reshape(-1, 2) \n",
    "print(reshaped_t.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.view(m, ...,)`: It does the same thing as reshape, but behaves differently from a memory perspective. See the documentation for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 1247])\n",
      "torch.Size([10, 2494, 1])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.arange(24940)\n",
    "viewed_t1 = t3.view(5, 4, -1)\n",
    "viewed_t2 = t3.reshape(10, -1, 1)\n",
    "print(viewed_t1.shape)\n",
    "print(viewed_t2.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Stacking and Concatenation : `cat() stack()` \n",
    "Finally, we utilize cat() and stack() to concatenate tensors.\n",
    "`cat()` merges two tensors along the same axis. It is mainly used inside the model to combine tensors that go into the next hidden layer.\n",
    "The `stack()` function is mainly used to build mini-batches by stacking data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# The torch.cat() function merges two or more sequences of tensors (along a specific axis).\n",
    "# These tensors must have the same dimension.\n",
    "vec1 = tensor([1, 2, 3])\n",
    "vec2 = tensor([4, 5, 6])\n",
    "vec3 = tensor([7, 8, 9])\n",
    "vec4 = torch.cat([vec1, vec2, vec3])\n",
    "print(vec4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[1, 4, 7],\n",
      "        [2, 5, 8],\n",
      "        [3, 6, 9]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The stack() method stacks two or more tensors along a specific axis.\n",
    "batch_vec = torch.stack([vec1, vec2, vec3], dim=0)\n",
    "print(batch_vec)\n",
    "print(batch_vec.shape)\n",
    "\n",
    "batch_vec = torch.stack([vec1, vec2, vec3], dim=1)\n",
    "print(batch_vec)\n",
    "print(batch_vec.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pop Quiz 3\n",
    "1) Create a random vector of length 4096 using `arange()`\n",
    "2) Resize the vector to a square (64x64) matrix using one of the methods learned above using `reshape() or view()`\n",
    "3) Repeat steps 1 and 2 to create three square matrices, and then add a redundancy dimension of size 1 to the 0th axis of each tensor using `unsqueeze()`\n",
    "4) Exchange the 0th axis and the last axis using `transpose()`\n",
    "5) Put three square matrices in a list and synthesize the tensor based on the last axis -> You should get a 64x64x3 tensor using `cat()`\n",
    "6) Repeat the above process 4 times to stack 64x64x3 to create a 4 x 64 x 64 x 3 tensor using `stack()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1030)\n",
    "# code : \n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pop Quiz 4\n",
    "1. Re-implement as a torch component of Policy Class implemented in Pop Quiz presented in Class.ipynb.\n",
    "\n",
    "#### Policy class requirements\n",
    "- `__init__(self, state_dim, act_dim)`:\n",
    "   - Function: Receives state_dimension and action_dimension as input and stores them as member variables.\n",
    "   - A random matrix with the shape of [aciton_dim, state_dim] is stored in self.weight. (Hint. Use the `torch.randn` method)\n",
    "- `__call__(self, state)`:\n",
    "   - Function: internally calls get_dist() and returns the result.\n",
    "\n",
    "- `get_dist(self, state)`:\n",
    "   - This function takes state as input and returns distribution.\n",
    "   - Obtain a linearly transformed vector through matrix multiplication of self.weight and state. Matrix multiplication is computed in the same way as `mat3 = mat1 @ mat2` .\n",
    "   - Pass the linearized vector through a nonlinear function in the same way as nonlinear_vector = `relu(vector)`.\n",
    "   - Apply the `softmax` function to the calculated vector to obtain the probability distribution `probs`.\n",
    "   - Get the categorical distribution `dist` via `dist=Categorical(probs)` and return it.\n",
    "  \n",
    "- `get_action(self, dist)`:\n",
    "   - Function: Take distribution as input, sample action_index and return.\n",
    "   - Return action_index through `dist.sample()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax, relu\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "class Policy:\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        pass\n",
    "    \n",
    "    def get_dist(self, state):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, state):\n",
    "        pass\n",
    "    \n",
    "    def get_action(self, dist):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "obs_dim = 8\n",
    "act_dim = 4\n",
    "policy = Policy(obs_dim, act_dim)\n",
    "\n",
    "state = torch.randn(8)\n",
    "dist = policy(state)\n",
    "action = policy.get_action(dist)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minerl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "266dbc1b53b3a75132c42213de358c469c42e7e8486df6091cb08cba7b9be0d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
